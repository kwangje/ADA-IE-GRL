{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import speechbrain as sb\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "from speechbrain.utils.parameter_transfer import Pretrainer\n",
    "\n",
    "from models.ADA_IE import ADA_IE\n",
    "from datasets.ADAIE_dataset import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speechbrain as sb\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "LABEL_DIR = '/media/beck/ssd/datasets_opensource/sr/processed_data'\n",
    "SPEAKER_ID_LIST = 'speaker_id_list_train_dc.json'\n",
    "AG_LIST = 'AG_list.json'\n",
    "C_ID_LIST = 'c_id_list.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder_spk = sb.dataio.encoder.CategoricalEncoder()\n",
    "label_encoder_ag = sb.dataio.encoder.CategoricalEncoder()\n",
    "label_encoder_c = sb.dataio.encoder.CategoricalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@sb.utils.data_pipeline.takes(\"path\") # file_path\n",
    "@sb.utils.data_pipeline.provides(\"sig\")\n",
    "def audio_pipeline(path):\n",
    "\tsig = sb.dataio.dataio.read_audio(path)\n",
    "\treturn sig\n",
    "\n",
    "# Define label pipeline:\n",
    "@sb.utils.data_pipeline.takes(\"VoxCeleb_ID\") # speaker_id\n",
    "@sb.utils.data_pipeline.provides(\"speaker_id\", \"speaker_encoded\")\n",
    "def speaker_label_pipeline(speaker_id):\n",
    "\tyield speaker_id\n",
    "\tspeaker_encoded = label_encoder_spk.encode_label_torch(speaker_id, True)\n",
    "\tyield speaker_encoded\n",
    "\n",
    "# Define label pipeline:\n",
    "@sb.utils.data_pipeline.takes(\"agegroup\")\n",
    "@sb.utils.data_pipeline.provides(\"agegroup\", \"agegroup_encoded\")\n",
    "def agegroup_label_pipeline(agegroup):\n",
    "\tyield agegroup\n",
    "\tagegroup_encoded = label_encoder_ag.encode_label_torch(agegroup, True)\n",
    "\tyield agegroup_encoded\n",
    "\n",
    "@sb.utils.data_pipeline.takes(\"child_id\")\n",
    "@sb.utils.data_pipeline.provides(\"child_id\", \"c_encoded\")\n",
    "def child_id_label_pipeline(child_id):\n",
    "\tyield child_id\n",
    "\tc_encoded = label_encoder_c.encode_label_torch(child_id, True)\n",
    "\tyield c_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/beck/ssd/datasets_opensource/sr/augment/rirs_noises.zip exists. Skipping download\n"
     ]
    }
   ],
   "source": [
    "# hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "hparams_file = \"./yaml/ADA_IE.yaml\"\n",
    "# sb.utils.distributed.ddp_init_group(run_opts)\n",
    "\n",
    "with open(hparams_file) as fin:\n",
    "\thparams = load_hyperpyyaml(fin)  # , overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_create_label_encoder(label_enc_file,\n",
    "\t\t\t\t\t\t\t\tlabel_encoder,\n",
    "\t\t\t\t\t\t\t\tlabel_list_file = None,\n",
    "\t\t\t\t\t\t\t\t):\n",
    "\tlabel_list = None\n",
    "\t\n",
    "\twith open(os.path.join(LABEL_DIR, label_list_file), 'r') as f:\n",
    "\t\tlabel_list = [tuple(json.load(f))]\n",
    "\n",
    "\tlab_enc_file = os.path.join(hparams[\"save_folder\"], label_enc_file)\n",
    "\tlabel_encoder.load_or_create(\n",
    "\t\tpath=lab_enc_file,\n",
    "\t\tsequence_input=False,\n",
    "\t\tfrom_iterables=label_list,\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "\n",
    "for dataset in [\"train\", \"dev\", \"eval\"]:\n",
    "\tdatasets[dataset] = sb.dataio.dataset.DynamicItemDataset.from_json(\n",
    "\t\tjson_path=hparams[f\"{dataset}_annotation\"],\n",
    "\t\treplacements={\"data_root\": hparams[\"data_folder\"]},\n",
    "\t\tdynamic_items=[\n",
    "\t\t\t\t\t\taudio_pipeline,\n",
    "\t\t\t\t\t\tspeaker_label_pipeline,\n",
    "\t\t\t\t\t\tagegroup_label_pipeline,\n",
    "\t\t\t\t\t\tchild_id_label_pipeline,\n",
    "\t\t\t\t\t#    triplet_label_pipeline\n",
    "\t\t\t\t\t\t],\n",
    "\t\toutput_keys=[\"id\", \"sig\",\n",
    "\t\t\t\t\t\"speaker_id\", \"speaker_encoded\",\n",
    "\t\t\t\t\t\"agegroup\", \"agegroup_encoded\",\n",
    "\t\t\t\t\t\"child_id\", \"c_encoded\", \n",
    "\t\t\t\t\t# \"triplet_encoded\"\n",
    "\t\t\t\t\t\t],\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2741"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_create_label_encoder(label_enc_file=\"label_encoder_speaker.txt\",\n",
    "\t\t\t\t\t\t\tlabel_encoder=label_encoder_spk,\n",
    "\t\t\t\t\t\t\tlabel_list_file=SPEAKER_ID_LIST\n",
    "\t\t\t\t\t\t)\n",
    "label_encoder_spk.add_unk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_create_label_encoder(label_enc_file=\"label_encoder_ag.txt\",\n",
    "                            label_encoder=label_encoder_ag,\n",
    "                            label_list_file=AG_LIST\n",
    "                        )\n",
    "label_encoder_ag.add_unk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<speechbrain.dataio.encoder.CategoricalEncoder at 0x7fb661c7a9d0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_create_label_encoder(label_enc_file,\n",
    "\t\t\t\t\t\t\t\tlabel_encoder,\n",
    "\t\t\t\t\t\t\t\tlabel_list_file = None,\n",
    "\t\t\t\t\t\t\t\t):\n",
    "\tlabel_list = None\n",
    "\t\n",
    "\twith open(os.path.join(LABEL_DIR, label_list_file), 'r') as f:\n",
    "\t\tlabel_list = [tuple(json.load(f))]\n",
    "\n",
    "\tlab_enc_file = os.path.join(hparams[\"save_folder\"], label_enc_file)\n",
    "\tlabel_encoder.load_or_create(\n",
    "\t\tpath=lab_enc_file,\n",
    "\t\tsequence_input=False,\n",
    "\t\tfrom_iterables=label_list,\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beck/.pyenv/versions/3.7.10/envs/ada/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import speechbrain as sb\n",
    "from hyperpyyaml import load_hyperpyyaml\n",
    "from speechbrain.utils.parameter_transfer import Pretrainer\n",
    "\n",
    "from models.ADA_IE import ADA_IE\n",
    "from datasets.ADAIE_dataset import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/beck/ssd/datasets_opensource/sr/augment/rirs_noises.zip exists. Skipping download\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beck/.pyenv/versions/3.7.10/envs/ada/lib/python3.7/site-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "# hparams_file, run_opts, overrides = sb.parse_arguments(sys.argv[1:])\n",
    "hparams_file = \"./yaml/ADA_IE.yaml\"\n",
    "# sb.utils.distributed.ddp_init_group(run_opts)\n",
    "\n",
    "with open(hparams_file) as fin:\n",
    "\thparams = load_hyperpyyaml(fin)  # , overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain = Pretrainer(loadables={'model': hparams['modules']['fbanks_encoder']},\n",
    "\t\t\t\t\t\tpaths={'model': \"speechbrain/spkrec-ecapa-voxceleb/embedding_model.ckpt\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cached_download() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_459016/38645051.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpretrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.10/envs/ada/lib/python3.7/site-packages/speechbrain/utils/parameter_transfer.py\u001b[0m in \u001b[0;36mcollect_files\u001b[0;34m(self, default_source)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 )\n\u001b[1;32m    181\u001b[0m             path = fetch(\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_filename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msave_filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             )\n\u001b[1;32m    184\u001b[0m             \u001b[0mloadable_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.10/envs/ada/lib/python3.7/site-packages/speechbrain/pretrained/fetching.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(filename, source, savedir, overwrite, save_filename, use_auth_token)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhuggingface_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhf_hub_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mfetched_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhuggingface_hub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcached_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;31m# Huggingface hub downloads to etag filename, symlink to the expected one:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0msourcepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cached_download() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "pretrain.collect_files()\n",
    "pretrain.load_collected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42d7b2bd752dd3d8e8879dfd3a73d4fbe9d0f999ba1495b72af448500479ee8a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
